
import os

os.getcwd()
os.chdir('C:\\Users\\sxw17\\Desktop\\python learning\\Python for Finance\\Python_Programming_for_Finance')

import bs4 as bs
import pickle
import requests
import datetime as dt
import pandas as pd

import fix_yahoo_finance as fy

fy.pdr_override()

from pandas.api.types import is_list_like

pd.core.common.is_list_like = pd.api.types.is_list_like

import pandas_datareader.data as web
import fix_yahoo_finance as yf
from pandas_datareader import data as pdr

yf.pdr_override()


def save_sp500_tickers():
    response = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')
    soup = bs.BeautifulSoup(response.text)

    table = soup.find('table', {'class': "wikitable sortable"})
    tickers = []

    for row in table.findAll('tr')[1:]:
        ticker = row.findAll('td')[0].text

        ticker = ticker[:-1]
        '''
        mapping=str.maketrans(".","-")
        ticker=ticker.translate(mapping)
        '''
        ticker = str(ticker).replace('.', '-')
        tickers.append(ticker)

    with open('sp500tickers.pickle', 'wb') as f:
        pickle.dump(tickers, f)

    print(tickers)
    return tickers


save_sp500_tickers()

# AAP

fail_names = []


def get_data_from_yahoo(reload_sp500=False):
    if reload_sp500:
        tickers = save_sp500_tickers()

    else:
        with open('sp500tickers.pickle', 'rb') as f:
            tickers = pickle.load(f)

    if not os.path.exists('stock_dfs'):
        os.makedirs('stock_dfs')

    '''
    start_date = dt.datetime.strptime('2000-1-1',"%Y-%m-%d")
    end_date = dt.datetime.strptime('2019-7-5',"%Y-%m-%d")
    '''
    start_date = dt.datetime(2000, 1, 1)
    end_date = dt.datetime(2019, 7, 5)

    for ticker in tickers:
        # print(ticker)
        try:
            if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):
                df = web.DataReader(ticker, 'yahoo', start_date, end_date)
                df.to_csv('stock_dfs/{}.csv'.format(ticker))
            else:
                print("Already have {}".format(ticker))
        except:
            print(ticker + " was failed")
            fail_names.append(ticker)


get_data_from_yahoo()

print(fail_names)
start_date = dt.datetime(2000, 1, 1)
end_date = dt.datetime(2019, 7, 5)

fail_names_term2 = []

for ticker in fail_names:
    try:
        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):
            df = web.DataReader(ticker, 'yahoo', start_date, end_date)
            df.to_csv('stock_dfs/{}.csv'.format(ticker))
        else:
            print("Already have {}".format(ticker))
    except:
        print(ticker + " was failed")
        fail_names_term2.append(ticker)
        pass

fail_names_term3 = []

for ticker in fail_names_term2:
    try:
        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):
            df = web.DataReader(ticker, 'yahoo', start_date, end_date)
            df.to_csv('stock_dfs/{}.csv'.format(ticker))
        else:
            print("Already have {}".format(ticker))
    except:
        print(ticker + " was failed")
        fail_names_term3.append(ticker)
        pass

fail_names_term4 = []

for ticker in fail_names_term3:
    try:
        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):
            df = web.DataReader(ticker, 'yahoo', start_date, end_date)
            df.to_csv('stock_dfs/{}.csv'.format(ticker))
        else:
            print("Already have {}".format(ticker))
    except:
        print(ticker + " was failed")
        fail_names_term4.append(ticker)
        pass


###########################################
# test for reviews


def get_data_from_yahoo(reload_sp500=False):
    if reload_sp500:
        tickers = save_sp500_tickers()

    else:
        with open('sp500tickers.pickle', 'rb') as f:
            tickers = pickle.load(f)

    if not os.path.exists('stock_dfs'):
        os.makedirs('stock_dfs')

    '''
    start_date = dt.datetime.strptime('2000-1-1',"%Y-%m-%d")
    end_date = dt.datetime.strptime('2019-7-5',"%Y-%m-%d")
    '''
    start_date = dt.datetime(2000, 1, 1)
    end_date = dt.datetime(2019, 7, 5)

    for ticker in tickers:
        # print(ticker)

        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):
            df = web.DataReader(ticker, 'yahoo', start_date, end_date)
            df.to_csv('stock_dfs/{}.csv'.format(ticker))
        else:
            print("Already have {}".format(ticker))


get_data_from_yahoo()

